@ARTICLE{DatasetPaper,
AUTHOR={Simões, Marco and Borra, Davide and Santamaría-Vázquez, Eduardo and , GBT-UPM and Bittencourt-Villalpando, Mayra and Krzemiński, Dominik and Miladinović, Aleksandar and , Neural_Engineering_Group and Schmid, Thomas and Zhao, Haifeng and Amaral, Carlos and Direito, Bruno and Henriques, Jorge and Carvalho, Paulo and Castelo-Branco, Miguel},   
TITLE={BCIAUT-P300: A Multi-Session and Multi-Subject Benchmark Dataset on Autism for P300-Based Brain-Computer-Interfaces},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={14},           
YEAR={2020},      
URL={https://www.frontiersin.org/articles/10.3389/fnins.2020.568104},       
DOI={10.3389/fnins.2020.568104},      
ISSN={1662-453X},   
ABSTRACT={There is a lack of multi-session P300 datasets for Brain-Computer Interfaces (BCI). Publicly available datasets are usually limited by small number of participants with few BCI sessions. In this sense, the lack of large, comprehensive datasets with various individuals and multiple sessions has limited advances in the development of more effective data processing and analysis methods for BCI systems. This is particularly evident to explore the feasibility of deep learning methods that require large datasets. Here we present the BCIAUT-P300 dataset, containing 15 autism spectrum disorder individuals undergoing 7 sessions of P300-based BCI joint-attention training, for a total of 105 sessions. The dataset was used for the 2019 IFMBE Scientific Challenge organized during MEDICON 2019 where, in two phases, teams from all over the world tried to achieve the best possible object-detection accuracy based on the P300 signals. This paper presents the characteristics of the dataset and the approaches followed by the 9 finalist teams during the competition. The winner obtained an average accuracy of 92.3\% with a convolutional neural network based on EEGNet. The dataset is now publicly released and stands as a benchmark for future P300-based BCI algorithms based on multiple session data.}
}

@ARTICLE{ClinicalTrialPaper,
AUTHOR={Amaral, Carlos and Mouga, Susana and Simões, Marco and Pereira, Helena C. and Bernardino, Inês and Quental, Hugo and Playle, Rebecca and McNamara, Rachel and Oliveira, Guiomar and Castelo-Branco, Miguel},   
TITLE={A Feasibility Clinical Trial to Improve Social Attention in Autistic Spectrum Disorder (ASD) Using a Brain Computer Interface},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={12},           
YEAR={2018},      
URL={https://www.frontiersin.org/articles/10.3389/fnins.2018.00477},       
DOI={10.3389/fnins.2018.00477},      
ISSN={1662-453X},   
ABSTRACT={Deficits in the interpretation of others' intentions from gaze-direction or other social attention cues are well-recognized in ASD. Here we investigated whether an EEG brain computer interface (BCI) can be used to train social cognition skills in ASD patients. We performed a single-arm feasibility clinical trial and enrolled 15 participants (mean age 22y 2m) with high-functioning ASD (mean full-scale IQ 103). Participants were submitted to a BCI training paradigm using a virtual reality interface over seven sessions spread over 4 months. The first four sessions occurred weekly, and the remainder monthly. In each session, the subject was asked to identify objects of interest based on the gaze direction of an avatar. Attentional responses were extracted from the EEG P300 component. A final follow-up assessment was performed 6-months after the last session. To analyze responses to joint attention cues participants were assessed pre and post intervention and in the follow-up, using an ecologic “Joint-attention task.” We used eye-tracking to identify the number of social attention items that a patient could accurately identify from an avatar's action cues (e.g., looking, pointing at). As secondary outcome measures we used the Autism Treatment Evaluation Checklist (ATEC) and the Vineland Adaptive Behavior Scale (VABS). Neuropsychological measures related to mood and depression were also assessed. In sum, we observed a decrease in total ATEC and rated autism symptoms (Sociability; Sensory/Cognitive Awareness; Health/Physical/Behavior); an evident improvement in Adapted Behavior Composite and in the DLS subarea from VABS; a decrease in Depression (from POMS) and in mood disturbance/depression (BDI). BCI online performance and tolerance were stable along the intervention. Average P300 amplitude and alpha power were also preserved across sessions. We have demonstrated the feasibility of BCI in this kind of intervention in ASD. Participants engage successfully and consistently in the task. Although the primary outcome (rate of automatic responses to joint attention cues) did not show changes, most secondary neuropsychological outcome measures showed improvement, yielding promise for a future efficacy trial.(clinical-trial ID: NCT02445625—clinicaltrials.gov).}
}

@article{ClinicalTrialTechnicalPaper,
title = {A novel Brain Computer Interface for classification of social joint attention in autism and comparison of 3 experimental setups: A feasibility study},
journal = {Journal of Neuroscience Methods},
volume = {290},
pages = {105-115},
year = {2017},
issn = {0165-0270},
doi = {https://doi.org/10.1016/j.jneumeth.2017.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0165027017302728},
author = {Carlos P. Amaral and Marco A. Simões and Susana Mouga and João Andrade and Miguel Castelo-Branco},
keywords = {Brain-computer interface, EEG, Virtual reality, Dry electrodes, Social attention},
abstract = {Background
We present a novel virtual-reality P300-based Brain Computer Interface (BCI) paradigm using social cues to direct the focus of attention. We combined interactive immersive virtual-reality (VR) technology with the properties of P300 signals in a training tool which can be used in social attention disorders such as autism spectrum disorder (ASD).
New method
We tested the novel social attention training paradigm (P300-based BCI paradigm for rehabilitation of joint-attention skills) in 13 healthy participants, in 3 EEG systems. The more suitable setup was tested online with 4 ASD subjects. Statistical accuracy was assessed based on the detection of P300, using spatial filtering and a Naïve-Bayes classifier.
Results
We compared: 1 – g.Mobilab+ (active dry-electrodes, wireless transmission); 2 – g.Nautilus (active electrodes, wireless transmission); 3 – V-Amp with actiCAP Xpress dry-electrodes. Significant statistical classification was achieved in all systems. g.Nautilus proved to be the best performing system in terms of accuracy in the detection of P300, preparation time, speed and reported comfort. Proof of concept tests in ASD participants proved that this setup is feasible for training joint attention skills in ASD.
Comparison with existing methods
This work provides a unique combination of ‘easy-to-use’ BCI systems with new technologies such as VR to train joint-attention skills in autism.
Conclusions
Our P300 BCI paradigm is feasible for future Phase I/II clinical trials to train joint-attention skills, with successful classification within few trials, online in ASD participants. The g.Nautilus system is the best performing one to use with the developed BCI setup.}
}


@incollection{PalaniPaper,
           month = {09},
          author = {Bipra Chatterjee and Palaniappan Ramaswamy and Cota Navin Gupta},
          series = {IFMBE Proceedings},
       booktitle = {XV Mediterranean Conference on Medical and Biological Engineering and Computing ? MEDICON 2019},
          editor = {Jorge Henriques and Nuno Neves and Paolo de Carvalho},
           title = {Performance Evaluation of Manifold Algorithms on a P300 Paradigm Based Online BCI Dataset},
         address = {Cham, Switzerland},
       publisher = {Springer},
            year = {2019},
         journal = {Proceedings of XV Mediterranean Conference on Medical and Biological Engineering and Computing ? MEDICON 2019},
           pages = {1894--1898},
        keywords = {Brain-Computer Interfaces, CNN, BLDA, RUSBoosting},
             url = {https://kar.kent.ac.uk/79906/},
        abstract = {Healthcare field is highly benefited by incorporating BCI for detection and diagnosis of some health related detriment as well as rehabilitation and restoration of certain disabilities. An EEG dataset acquired from 15 high-functioning ASD patients, while they were undergoing a P300 experiment in a virtual reality platform, was analysed in this paper using three algorithms. Performance of Bayes Linear Discriminant Analysis (BLDA) was predominant over Convolutional Neural Network (CNN) and Random Undersampling (RUS) Boosting. BLDA rendered 73\% overall accuracy in predicting target and the best accuracy for each subject using CNN or BLDA yielded an overall accuracy of 76\%.}
}

@misc{layers,
  author = {MathWorks(Layers)},
  title = {Specify Layers of Convolutional Neural Network},
  year = {2022},
  url = {https://uk.mathworks.com/help/deeplearning/ug/layers-of-a-convolutional-neural-network.html}
}

@misc{options,
  author = {MathWorks(TrainingOptions)},
  title = {TrainingOptions: Options for training deep learning neural network},
  year = {2022},
  url = {https://uk.mathworks.com/help/deeplearning/ref/trainingoptions.html}
}

@misc{Kaggle,
  author = {Marco Simões(Kaggle)},
  title = {BCIAUT\_P300: Multi-Session and Multi-Subject Benchmark Dataset on Autism for P300-BCI},
  year = {2020},
  url = {https://www.kaggle.com/datasets/disbeat/bciaut-p300}
}

@misc{whatiscnn,
  author = {MathWorks(CNN)},
  title = {What is a Convolutional Neural Network?},
  year = {2022},
  url = {https://uk.mathworks.com/discovery/convolutional-neural-network-matlab.html#how-they-work}
}

@INPROCEEDINGS{UnderstandCNN,
  author={Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
  booktitle={2017 International Conference on Engineering and Technology (ICET)}, 
  title={Understanding of a convolutional neural network}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICEngTechnol.2017.8308186}}


@misc{buttord,
  author = {MathWorks(Buttord)},
  title = {Buttord: Butterworth filter order and cutoff frequency},
  year = {2022},
  url = {https://www.mathworks.com/help/signal/ref/buttord.html}
}

@misc{butter,
  author = {MathWorks(Butter)},
  title = {Butter: Butterworth filter design},
  year = {2022},
  url = {https://www.mathworks.com/help/signal/ref/butter.html}
}

@incollection{Hoffmann,
          author = {Hoffmann, Ulrich, et al.},
           title = {Performance Evaluation of Manifold Algorithms on a P300 Paradigm Based Online BCI Dataset},
       publisher = {Journal of Neuroscience Methods 167.1},
            year = {2008},
         journal = {167.1},
           pages = {115-125}
}

@ARTICLE{RUS,
  author={Seiffert, Chris and Khoshgoftaar, Taghi M. and Van Hulse, Jason and Napolitano, Amri},
  journal={IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans}, 
  title={RUSBoost: A Hybrid Approach to Alleviating Class Imbalance}, 
  year={2010},
  volume={40},
  number={1},
  pages={185-197},
  doi={10.1109/TSMCA.2009.2029559}
}

@ARTICLE{7P300CNN,
  author={Cecotti, Hubert and Graser, Axel},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces}, 
  year={2011},
  volume={33},
  number={3},
  pages={433-445},
  doi={10.1109/TPAMI.2010.125}}

@article{8EEGCNN,
author = {Lawhern, Vernon and Solon, Amelia and Waytowich, Nicholas and Gordon, Stephen and Hung, Chou and Lance, Brent},
year = {2016},
month = {11},
pages = {},
title = {EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces},
volume = {15},
journal = {Journal of Neural Engineering},
doi = {10.1088/1741-2552/aace8c}
}