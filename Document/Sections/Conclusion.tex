To conclude the research undertaken in this paper but evaluating the project objectives laid out in \cref{Project Objectives Section} was to improve previous research undertaken by \cite{PalaniPaper} which gave two accuracy's 67\% for session 4 to 7 and 76\% an average calculated for all subjects using the strongest session accuracy. All four objectives were carried out and completed, by forming new baseline test accuracy's using the same features as used by \cite{PalaniPaper} which yielded 59\% and 78\% respectively. The highest average accuracy for sessions 4 to 7 was 63.8\%, which is 4\% greater than my baseline accuracy but 3\% lower than the objective accuracy for that test. The test placed the dropout layer after the max pooling layer where all 3 dropout probabilities were lowered to 0.1\%, holding a value of 50 max epochs and an initial learn rate of 0.005, the rest of the CNN features and values were that of the original CNN. \\


In regard to all of the sessions (1 to 7) for all subject, where the session with highest value of each subject was averaged out to obtained 83.87\%, which is 6\% greater than my baseline accuracy and 8\% greater than the objective accuracy. This was achieved by again alter the dropout layer after the max pooling layer with its probabilities set to 0.1\%, 30 epochs, an initial learn rate of 0.005 and the output size set to 64 on the first fully connected layer. The dataset contains all 105 sessions spanning over 15 subjects, achievement of gaining 83.86\% yields the most rewards as to serve the entire dataset not just a half of it as acquired in session 4 to 7 or session 1 to 3. It was found that all the subjects effect the CNN differently with subjects: 2, 4, 8, 10 and 15 outperforming the other subject consistently. The sessions held a correlation in which the accuracy was always high after on specific sessions of that subject, thus being highly subject dependent. \\

The CNN was updated from MATLAB 2019a to 2022a by replacing outdated commands updating the files for future work. This improved the efficiency of the MATLAB code and the run time of the simulations, though the run time hindered that number of variations that could be tested. Run each variation lasted up to 8/9 hours, depending of how many sessions were ran. This sets the foundation for future improvement as to explore tailoring of the CNN to this dataset to improve the accuracy and or efficiency. \\

With respect to the large run time of each test, the original project object was not completed in respect to the work completed in (\cite{PalaniPaper}), where BLDA and RUS were not observed or trailed. The cause was the lack of time available and CNN was pursued under the advice of future improvement, â€˜It is possible with skewness of the data corrected and deeper structures, CNN may produce improved results.' (\cite{PalaniPaper}).